{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ac5674",
   "metadata": {},
   "source": [
    "# 17 Category Flower Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef271fb9",
   "metadata": {},
   "source": [
    "## Part 1 - Observing Results from 2006 Paper\n",
    "Observe the results from the 2006 paper using the precomputed feature distance matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b1efb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789279c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "gdrive_dir = '/gdrive'\n",
    "drive.mount(gdrive_dir)\n",
    "gdrive_dir = gdrive_dir+'/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28914fa",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8df9a17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'trn1', 'trn2', 'trn3', 'tst1', 'tst2', 'tst3', 'val3', 'val2', 'val1'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasplits = scipy.io.loadmat('datasplits.mat')\n",
    "datasplits.keys() # Observe keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839de245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 680)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasplits['trn1'].shape # What do the train splits look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a2097e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 340)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasplits['tst1'].shape # What do the test splits look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d42bcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(datasplits['trn1'][0]) == set(datasplits['trn2'][0]) # Are the splits permuations of the same set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f6756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'D_colourgc', 'D_texturegc', 'D_shapegc'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distmtxs = scipy.io.loadmat('distancematrices17gcfeat06.mat')\n",
    "distmtxs.keys() # Observe keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a61b7901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1360, 1360)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distmtxs['D_shapegc'].shape # What do the distance matrices look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e926ec09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1360,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.repeat(range(17), 80) # Create a label array based on the ordering of the images\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-penetration",
   "metadata": {},
   "source": [
    "### Train kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "594d0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasplits['trn1'][0] # Only using one of 3 possible splits for this preliminary test\n",
    "test = datasplits['tst1'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed879221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the paper's results using the precomputed distance matrices\n",
    "model = KNeighborsClassifier(n_neighbors=5, metric='precomputed')\n",
    "model.fit(distmtxs['D_shapegc'][train, :][:, train], labels[train])\n",
    "y_pred = model.predict(distmtxs['D_shapegc'][test, :][:, train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5bf9a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5294117647058824"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels[test], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14a7cf",
   "metadata": {},
   "source": [
    "Not sure why the accuracy is so low. Could have something to do with multiple hypotheses as discussed in the paper which I'm not sure I understand. Not going to worry for now since this was just meant as a sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b862d",
   "metadata": {},
   "source": [
    "## Part 2 - Transfer Learning with PyTorch\n",
    "Use transfer learning, freezing convolutional layers but training new classification layers to work with flower images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05407609",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48ebf163",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, models\n",
    "from collections import OrderedDict\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c47d5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation to the input ResNet expects\n",
    "resnet_mean = np.array([0.485, 0.456, 0.406])\n",
    "resnet_std = np.array([0.229, 0.224, 0.225])\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=resnet_mean, std=resnet_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22773d29",
   "metadata": {},
   "source": [
    "### Load images\n",
    "**NB** I restructed nature of the jpg directory that was downloaded from http://www.robots.ox.ac.uk/~vgg/data/flowers/17/index.html to make it easier to use Torch's ImageLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37c7bae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 1: 680 images / 85 batches\n",
      "Valid set 1: 340 images / 43 batches\n",
      "Test set 1:  340 images / 43 batches\n"
     ]
    }
   ],
   "source": [
    " # All the images\n",
    "fullset = ImageFolder('jpg', transform=preprocess)\n",
    "\n",
    "# Split keys - names of splits (might as well use splits already computed in paper)\n",
    "splitkeys = ['trn1', 'trn2', 'trn3', 'val1', 'val2', 'val3', 'tst1', 'tst2', 'tst3', ]\n",
    "\n",
    "# Image datasets as given by the paper's splits\n",
    "datasets = {key : Subset(fullset, datasplits[key][0]) for key in splitkeys} \n",
    "\n",
    "# Image loaders from the datasets\n",
    "dataloaders = {key : DataLoader(datasets[key], batch_size=8, shuffle=False, num_workers=4) for key in splitkeys}\n",
    "print(f\"Train set 1: {len(datasets['trn1'])} images / {len(dataloaders['trn1'])} batches\")\n",
    "print(f\"Valid set 1: {len(datasets['val1'])} images / {len(dataloaders['val1'])} batches\")\n",
    "print(f\"Test set 1:  {len(datasets['tst1'])} images / {len(dataloaders['tst1'])} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb644215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bluebell',\n",
       " 'buttercup',\n",
       " 'coltsfoot',\n",
       " 'cowslip',\n",
       " 'crocus',\n",
       " 'daffodil',\n",
       " 'daisy',\n",
       " 'dandelion',\n",
       " 'fritillary',\n",
       " 'iris',\n",
       " 'lilyvalley',\n",
       " 'pansy',\n",
       " 'snowdrop',\n",
       " 'sunflower',\n",
       " 'tigerlily',\n",
       " 'tulip',\n",
       " 'windflower']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = fullset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4474e10",
   "metadata": {},
   "source": [
    "### View some images\n",
    "**This is mostly copied from the PyTorch tutorial**  https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "731fecf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef imshow(img):\\n    # Un-normalize\\n    for i in range(img.shape[0]):\\n        img[i] = img[i] * resnet_std[i] + resnet_mean[i]\\n    \\n    npimg = img.numpy()\\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\\n    plt.show()\\n\\n# Get some random training images\\ndataiter = iter(dataloaders['trn1'])\\nimages, labels = dataiter.next()\\n\\n# Show images\\n#fig = plt.figure(figsize=(15, 120))\\nimshow(torchvision.utils.make_grid(images))\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def imshow(img):\n",
    "    # Un-normalize\n",
    "    for i in range(img.shape[0]):\n",
    "        img[i] = img[i] * resnet_std[i] + resnet_mean[i]\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images\n",
    "dataiter = iter(dataloaders['trn1'])\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Show images\n",
    "#fig = plt.figure(figsize=(15, 120))\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a7c08",
   "metadata": {},
   "source": [
    "### Configure transfer learning CNN\n",
    "Using becase its pretty light and easy to use with transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1eea9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Match the FC input layer (25088) to the output number of classes (17) with one hidden layer of 4096\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                          ('fc1', nn.Linear(25088, 4096)),\n",
    "                          ('relu', nn.ReLU()),\n",
    "                          ('fc2', nn.Linear(4096, 17)),\n",
    "                          ('output', nn.LogSoftmax(dim=1))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the pretrained weights\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the classifier portion of VGG19\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e1e21f",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0124919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criteria, optimizer, scheduler, datasplit=1,   \n",
    "                                      num_epochs=20, device='cuda'):\n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {} / {}'.format(epoch, num_epochs - 1))\n",
    "        \n",
    "        # Iterate through train and validation phases\n",
    "        for phase in ['trn', 'val']:\n",
    "            if phase is 'trn':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase + datasplit]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Set parameter gradients to zero\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward propagatation\n",
    "                with torch.set_grad_enabled(phase is 'trn'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward propagation\n",
    "                    # Optimize only if in training phase\n",
    "                    if phase is 'trn':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Compute statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f}, Accuracy: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Save this model \n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                wts_best = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53078fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following hyperparameters are used\n",
    "\n",
    "# Negative log likelihood loss - good with softmax output\n",
    "criteria = nn.NLLLoss()\n",
    "\n",
    "# Use Adam optimizer\n",
    "optim = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Decrease LR by a factor of 4 for each optimization\n",
    "sched = lr_scheduler.StepLR(optim, step_size=4, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaacadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = train_model(model, criteria, optim, sched, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733d007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
